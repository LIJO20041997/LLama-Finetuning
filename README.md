### 1. Fine-Tuning with Unsloth/Llama-3.2-1B-Instruct (Quantized Model)

This project demonstrates a  fine-tuning process using the quantized unsloth/Llama-3.2-1B-Instruct model with the "yahma/alpaca-cleaned" dataset from Hugging Face.

- Parameter Efficient Fine-Tuning (PEFT): Utilized PEFT for memory-efficient training, optimizing only essential parameters.
- Prompt Formatting: Pre-processed and formatted prompts to align with the target instruction style of the model.
- SFTTrainer: Leveraged the SFTTrainer class to fine-tune the model with the formatted data.
- Model Saving: The fine-tuned model was saved locally for easy access and deployment.

### 2. Fine-Tunned_Agricultural model

This project demonstrates a  fine-tuning process using the quantized unsloth/Llama-3.2-1B-Instruct model with the "KisanVaani/agriculture-qa-english-only" dataset from Hugging Face.

- Parameter Efficient Fine-Tuning (PEFT): Utilized PEFT for memory-efficient training, optimizing only essential parameters.
- Prompt Formatting: Pre-processed and formatted prompts to align with the target instruction style of the model.
- SFTTrainer: Leveraged the SFTTrainer class to fine-tune the model with the formatted data.
- Model Saving: The fine-tuned model was saved locally for easy access and deployment.







